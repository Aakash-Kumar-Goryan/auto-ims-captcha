{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (AveragePooling2D, Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D, ZeroPadding2D) \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from tensorflow.python.keras import backend as k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTCHA_DIR=os.path.join(\"data\",\"data-new\")\n",
    "DIGITS_DIR=os.path.join(\"data\",\"captcha-digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for digit:  9\n",
      "Processing for digit:  0\n",
      "Processing for digit:  7\n",
      "Processing for digit:  6\n",
      "Processing for digit:  1\n",
      "Processing for digit:  8\n",
      "Processing for digit:  4\n",
      "Processing for digit:  3\n",
      "Processing for digit:  2\n",
      "Processing for digit:  5\n"
     ]
    }
   ],
   "source": [
    "def loadData():\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in os.scandir(DIGITS_DIR):\n",
    "        if i.is_dir():\n",
    "            print(\"Processing for digit: \",i.name)\n",
    "            for j in os.scandir(i.path):\n",
    "                #print(j.name)\n",
    "                img = cv2.imread(j.path,0)\n",
    "#                 cv2.imshow(\"img\", img)\n",
    "#                 cv2.waitKey(1)\n",
    "#                 img = np.reshape(img, (20*20))\n",
    "                x.append(img)\n",
    "#                 x.append(np.reshape(img, (length, width, -1)))\n",
    "                label = i.name\n",
    "                y.append(int(label))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "#     cv2.destroyAllWindows()\n",
    "    return x,y\n",
    "        \n",
    "X,Y = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a6de937b8>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5395, 20, 20) (5395,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5395, 400)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the images\n",
    "image_vector_size = 20*20\n",
    "X = X.reshape(X.shape[0], image_vector_size)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 training lables as one-hot encoded vectors:\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Convert to \"one-hot\" vectors using the to_categorical function\n",
    "num_classes = 10\n",
    "yEnc = to_categorical(Y, num_classes)\n",
    "print(\"First 5 training lables as one-hot encoded vectors:\\n\", yEnc[4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4046, 400), (1349, 400), (4046, 10), (1349, 10))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(X,yEnc)\n",
    "xtrain.shape,xtest.shape,ytrain.shape,ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 800)               320800    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 800)               640800    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 200)               160200    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 1,123,810\n",
      "Trainable params: 1,123,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (400, ) #20*20\n",
    "num_classes = 10 # ten unique digits\n",
    "\n",
    "# The input layer requires the special input_shape parameter which should match\n",
    "# the shape of our training data.\n",
    "model = Sequential([\n",
    "    Dense(units=800, activation='sigmoid', input_shape=input_shape),\n",
    "    Dense(units=800, activation='sigmoid', input_shape=input_shape),\n",
    "    Dense(units=200, activation='sigmoid', input_shape=input_shape),\n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3236 samples, validate on 810 samples\n",
      "Epoch 1/30\n",
      "3236/3236 [==============================] - 3s 968us/sample - loss: 0.0879 - accuracy: 0.2262 - val_loss: 0.0800 - val_accuracy: 0.3988\n",
      "Epoch 2/30\n",
      "3236/3236 [==============================] - 1s 262us/sample - loss: 0.0717 - accuracy: 0.4960 - val_loss: 0.0574 - val_accuracy: 0.6247\n",
      "Epoch 3/30\n",
      "3236/3236 [==============================] - 1s 237us/sample - loss: 0.0489 - accuracy: 0.7423 - val_loss: 0.0370 - val_accuracy: 0.8049\n",
      "Epoch 4/30\n",
      "3236/3236 [==============================] - 1s 236us/sample - loss: 0.0310 - accuracy: 0.8239 - val_loss: 0.0252 - val_accuracy: 0.8222\n",
      "Epoch 5/30\n",
      "3236/3236 [==============================] - 1s 235us/sample - loss: 0.0205 - accuracy: 0.8900 - val_loss: 0.0180 - val_accuracy: 0.8975\n",
      "Epoch 6/30\n",
      "3236/3236 [==============================] - 1s 286us/sample - loss: 0.0141 - accuracy: 0.9221 - val_loss: 0.0138 - val_accuracy: 0.9198\n",
      "Epoch 7/30\n",
      "3236/3236 [==============================] - 1s 320us/sample - loss: 0.0113 - accuracy: 0.9339 - val_loss: 0.0120 - val_accuracy: 0.9321\n",
      "Epoch 8/30\n",
      "3236/3236 [==============================] - 1s 268us/sample - loss: 0.0095 - accuracy: 0.9450 - val_loss: 0.0103 - val_accuracy: 0.9383\n",
      "Epoch 9/30\n",
      "3236/3236 [==============================] - 1s 312us/sample - loss: 0.0082 - accuracy: 0.9549 - val_loss: 0.0097 - val_accuracy: 0.9358\n",
      "Epoch 10/30\n",
      "3236/3236 [==============================] - 1s 301us/sample - loss: 0.0075 - accuracy: 0.9645 - val_loss: 0.0084 - val_accuracy: 0.9556\n",
      "Epoch 11/30\n",
      "3236/3236 [==============================] - 1s 283us/sample - loss: 0.0069 - accuracy: 0.9669 - val_loss: 0.0080 - val_accuracy: 0.9519\n",
      "Epoch 12/30\n",
      "3236/3236 [==============================] - 1s 281us/sample - loss: 0.0063 - accuracy: 0.9688 - val_loss: 0.0072 - val_accuracy: 0.9605\n",
      "Epoch 13/30\n",
      "3236/3236 [==============================] - 1s 261us/sample - loss: 0.0062 - accuracy: 0.9703 - val_loss: 0.0072 - val_accuracy: 0.9630\n",
      "Epoch 14/30\n",
      "3236/3236 [==============================] - 1s 237us/sample - loss: 0.0056 - accuracy: 0.9731 - val_loss: 0.0066 - val_accuracy: 0.9679\n",
      "Epoch 15/30\n",
      "3236/3236 [==============================] - 1s 235us/sample - loss: 0.0052 - accuracy: 0.9762 - val_loss: 0.0062 - val_accuracy: 0.9654\n",
      "Epoch 16/30\n",
      "3236/3236 [==============================] - 1s 298us/sample - loss: 0.0048 - accuracy: 0.9796 - val_loss: 0.0059 - val_accuracy: 0.9704\n",
      "Epoch 17/30\n",
      "3236/3236 [==============================] - 1s 274us/sample - loss: 0.0044 - accuracy: 0.9815 - val_loss: 0.0055 - val_accuracy: 0.9778\n",
      "Epoch 18/30\n",
      "3236/3236 [==============================] - 1s 263us/sample - loss: 0.0042 - accuracy: 0.9821 - val_loss: 0.0051 - val_accuracy: 0.9728\n",
      "Epoch 19/30\n",
      "3236/3236 [==============================] - 1s 270us/sample - loss: 0.0039 - accuracy: 0.9833 - val_loss: 0.0049 - val_accuracy: 0.9741\n",
      "Epoch 20/30\n",
      "3236/3236 [==============================] - 1s 245us/sample - loss: 0.0035 - accuracy: 0.9873 - val_loss: 0.0049 - val_accuracy: 0.9728\n",
      "Epoch 21/30\n",
      "3236/3236 [==============================] - 1s 238us/sample - loss: 0.0034 - accuracy: 0.9870 - val_loss: 0.0044 - val_accuracy: 0.9802\n",
      "Epoch 22/30\n",
      "3236/3236 [==============================] - 1s 274us/sample - loss: 0.0032 - accuracy: 0.9901 - val_loss: 0.0047 - val_accuracy: 0.9741\n",
      "Epoch 23/30\n",
      "3236/3236 [==============================] - 1s 272us/sample - loss: 0.0035 - accuracy: 0.9858 - val_loss: 0.0046 - val_accuracy: 0.9741\n",
      "Epoch 24/30\n",
      "3236/3236 [==============================] - 1s 321us/sample - loss: 0.0034 - accuracy: 0.9858 - val_loss: 0.0045 - val_accuracy: 0.9790\n",
      "Epoch 25/30\n",
      "3236/3236 [==============================] - 1s 287us/sample - loss: 0.0032 - accuracy: 0.9873 - val_loss: 0.0046 - val_accuracy: 0.9753\n",
      "Epoch 26/30\n",
      "3236/3236 [==============================] - 1s 294us/sample - loss: 0.0030 - accuracy: 0.9864 - val_loss: 0.0042 - val_accuracy: 0.9840\n",
      "Epoch 27/30\n",
      "3236/3236 [==============================] - 1s 293us/sample - loss: 0.0034 - accuracy: 0.9845 - val_loss: 0.0044 - val_accuracy: 0.9753\n",
      "Epoch 28/30\n",
      "3236/3236 [==============================] - 1s 375us/sample - loss: 0.0033 - accuracy: 0.9879 - val_loss: 0.0047 - val_accuracy: 0.9728\n",
      "Epoch 29/30\n",
      "3236/3236 [==============================] - 1s 277us/sample - loss: 0.0034 - accuracy: 0.9864 - val_loss: 0.0049 - val_accuracy: 0.9765\n",
      "Epoch 30/30\n",
      "3236/3236 [==============================] - 1s 296us/sample - loss: 0.0035 - accuracy: 0.9886 - val_loss: 0.0070 - val_accuracy: 0.9580\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=['accuracy'])\n",
    "history = model.fit(xtrain, ytrain, batch_size=500, epochs=30, verbose=True, validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0034037067676052795, 0.9799852)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating over Training Data\n",
    "loss, accuracy  = model.evaluate(xtest, ytest, verbose=False)\n",
    "loss ,accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
